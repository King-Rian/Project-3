{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/King-Rian/Project-3/blob/main/Attempts__Other_Options.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB8LAqVHJNt6"
      },
      "outputs": [],
      "source": [
        "# Install emoji library\n",
        "!pip install emoji\n",
        "!pip install torch\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import json\n",
        "import emoji\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import RobertaTokenizer, RobertaModel, AdamW, T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22uEypKAJceX"
      },
      "outputs": [],
      "source": [
        "# Retrieve the 'emojis.json' zippped file\n",
        "\n",
        "# Step 1: Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Extract the ZIP file\n",
        "with zipfile.ZipFile('emojis.json.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Step 3: Load the extracted JSON file\n",
        "emoji_file = 'emojis.json'\n",
        "\n",
        "# Using pandas\n",
        "emoji_df = pd.read_json(emoji_file)\n",
        "print(\"Dataset loaded successfully. Sample data:\")\n",
        "print(emoji_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvFHhX9mJuAk"
      },
      "outputs": [],
      "source": [
        "# Check the shape, features, and datatypes of the df\n",
        "emoji_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzcHBB0RJz3F"
      },
      "outputs": [],
      "source": [
        "# Set options to display all rows and columns\n",
        "pd.set_option('display.max_rows', None)  # Display all rows\n",
        "pd.set_option('display.max_columns', None)  # Display all columns\n",
        "\n",
        "# Create a new emojis DataFrame with 'name' and 'unicode'\n",
        "key_value_pairs_df = emoji_df[['name', 'unicode']]\n",
        "\n",
        "# Process the 'name' column to include : at the beginning and end of the emoji name\n",
        "key_value_pairs_df['name'] = key_value_pairs_df['name'].apply(\n",
        "    lambda x: f\":{x.split(':')[0].strip()}:\"  # Remove everything after the first colon and add colons\n",
        ")\n",
        "\n",
        "# Convert the unicode column to emoji symbols\n",
        "key_value_pairs_df['emoji'] = key_value_pairs_df['name'].apply(emoji.emojize)\n",
        "\n",
        "# Filter out rows where 'unicode' contains more than one Unicode value\n",
        "# We check for the number of spaces and ensure it is less than 1\n",
        "# Eliminating complex emojis and ZWJ sequence values\n",
        "filtered_df = key_value_pairs_df[key_value_pairs_df['unicode'].str.count(' ') < 1]\n",
        "\n",
        "# Remove rows where 'emoji' contains text with a beginning and ending ':' - which means that emoji was not found for that :name:\n",
        "filtered_df = key_value_pairs_df[~key_value_pairs_df['emoji'].str.match(r'^:.*:$')]\n",
        "\n",
        "# Create a new df and rename features to read for concatination with the next data set\n",
        "new_filtered_df = filtered_df[['name', 'emoji']]\n",
        "new_filtered_df = new_filtered_df.rename(columns={'name': 'label'})\n",
        "\n",
        "# Display the DataFrame with emoji symbols\n",
        "new_filtered_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc6VQhulJ3FC"
      },
      "outputs": [],
      "source": [
        "# Create an emoji dictionary with labels and their Unicode values from https://carpedm20.github.io/emoji/docs/index.html\n",
        "emoji_dict = {emoji.demojize(e): e for e in emoji.EMOJI_DATA}\n",
        "\n",
        "# Show how many key value pairs we retrieved from emoji library\n",
        "records = len(emoji_dict)\n",
        "print(f\"Number of records: {records}\")\n",
        "\n",
        "# Create new df for use in concatenation the two data frames\n",
        "emoji_dictionary_df = pd.DataFrame(emoji_dict.items(), columns=['label', 'emoji'])\n",
        "emoji_dictionary_df.head()\n",
        "#emoji_dictionary_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8zLo6nqJ8Mw"
      },
      "outputs": [],
      "source": [
        "# Concatentate both dataframes / sources and drop the index\n",
        "combined_emoji_df = pd.concat([emoji_dictionary_df, new_filtered_df], ignore_index=True)\n",
        "\n",
        "# Show the key pair data frame with training data\n",
        "combined_emoji_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCaeZAVrJ8BF"
      },
      "outputs": [],
      "source": [
        "# Remove : character used for outputting emoji (vs. unicode) and replace underscores with spaces\n",
        "combined_emoji_df['label'] = combined_emoji_df['label'].str.replace(':', '').str.replace('_', ' ')\n",
        "\n",
        "# Print output\n",
        "combined_emoji_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHBOhbhQKbM4"
      },
      "outputs": [],
      "source": [
        "# Save processed dataset\n",
        "combined_emoji_df.to_csv('processed_emojis.csv', index=False)\n",
        "\n",
        "# Display dataset\n",
        "print(combined_emoji_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4xEz2cb3YrVK"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Initialize the T5 tokenizer and model\n",
        "# Load the \"t5-small\" model and tokenizer from Hugging Face's transformers library\n",
        "# T5 (Text-to-Text Transfer Transformer) is a model capable of various NLP tasks\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Prepare data for T5\n",
        "# Convert the 'label' column to a list of input texts and the 'emoji' column to a list of target texts\n",
        "# These will be the input-output pairs for the model training\n",
        "input_texts = combined_emoji_df['label'].tolist()\n",
        "target_texts = combined_emoji_df['emoji'].tolist()\n",
        "\n",
        "# Tokenize inputs and targets\n",
        "# Tokenize input texts and target texts for the model, ensuring uniform tensor shapes\n",
        "# Apply padding and truncation to control the sequence length\n",
        "# max_length specifies the maximum token length for inputs and outputs\n",
        "input_encodings = tokenizer(input_texts, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
        "target_encodings = tokenizer(target_texts, padding=True, truncation=True, max_length=8, return_tensors=\"pt\")\n",
        "\n",
        "# Dataset and DataLoader\n",
        "# Define a custom dataset class for organizing the input and target encodings\n",
        "class EmojiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        # Initialize with tokenized inputs and targets\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples in the dataset\n",
        "        return len(self.inputs['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve a single sample (input, attention mask, and labels) by index\n",
        "        return {\n",
        "            'input_ids': self.inputs['input_ids'][idx],\n",
        "            'attention_mask': self.inputs['attention_mask'][idx],\n",
        "            'labels': self.targets['input_ids'][idx]\n",
        "        }\n",
        "\n",
        "# Create a dataset and data loader\n",
        "# Use the custom dataset class to organize tokenized inputs and targets\n",
        "# DataLoader splits the dataset into manageable batches for training\n",
        "dataset = EmojiDataset(input_encodings, target_encodings)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Training setup\n",
        "# Define an optimizer (AdamW) to update the model's parameters during training\n",
        "# Set the learning rate (lr) for the optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Set the model to training mode\n",
        "# This activates certain layers like dropout that are specific to training\n",
        "model.train()\n",
        "\n",
        "# Training loop\n",
        "# Train the model over multiple epochs\n",
        "for epoch in range(3):  # Train for 3 epochs\n",
        "    total_loss = 0  # Track the total loss for this epoch\n",
        "    for batch in data_loader:\n",
        "        # Zero the gradients to prevent accumulation from previous steps\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Extract input_ids, attention_mask, and labels from the batch\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        # Perform a forward pass and compute the loss\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss for this batch\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the loss for the current epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
        "\n",
        "# Save the model and tokenizer\n",
        "# This allows reloading the model later for inference or fine-tuning\n",
        "model.save_pretrained(\"emoji_t5_model\")\n",
        "tokenizer.save_pretrained(\"emoji_t5_model\")\n",
        "\n",
        "# Translate input text to emoji\n",
        "# Define a function to generate emoji translations from text inputs\n",
        "def translate_to_emoji(text):\n",
        "    # Set the model to evaluation mode (disables dropout layers)\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input text and convert it to a tensor\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=32, truncation=True)\n",
        "\n",
        "    # Generate output tokens using beam search for better quality translations\n",
        "    outputs = model.generate(input_ids, max_length=8, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode the generated tokens to a human-readable string\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the translation\n",
        "# Provide sample inputs to test the model's ability to generate emoji translations\n",
        "print(translate_to_emoji(\"happy\"))  # Expected to output an emoji for happiness\n",
        "print(translate_to_emoji(\"sad\"))    # Expected to output an emoji for sadness\n",
        "print(translate_to_emoji(\"love\"))   # Expected to output an emoji for love\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhoYyQNTKUPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8029d256-7afe-465d-9960-6428ddfca171"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Enhanced Emoji Translator!\n",
            "Type any phrase and press Enter to get an emoji.\n",
            "Type 'exit' to quit the program.\n",
            "Emoji: No matching emoji found.\n",
            "Emoji: 🇧🇭 🇺🇦 🧠 🚅 ⛈ 🌧 🚄 🌈 🏳‍🌈 🌦 🚆 ☔ 🇧🇭 🚆 🇺🇦 🌈\n",
            "Emoji: 🇧🇶 🇲🇬 🇳🇮 🗃 📇 🗂 🎠 🎏 🪚 🥕 💳 🎴 🪪 🤸‍♂ 🤸🏿‍♂ 🤸🏻‍♂ 🤸🏾‍♂ 🤸🏼‍♂ 🤸🏽‍♂ 🚔 🤸 🤸🏿 🤸🏻 🤸🏾 🤸🏼 🤸🏽 🪧 🚓 🚨 🏎 🚃 🧣 🛒 🚋 🤸‍♀ 🤸🏿‍♀ 🤸🏻‍♀ 🤸🏾‍♀ 🤸🏼‍♀ 🤸🏽‍♀ 🧕 🧕🏿 🧕🏻 🧕🏾 🧕🏼 🧕🏽 🥕 🇲🇬 🇳🇮\n",
            "Emoji: 🥖 🍞 🫓 🥙 🍞\n",
            "Emoji: 🪺\n",
            "Emoji: ✈ 🛬 🛫 🪐 🛩 ✈️\n",
            "Emoji: 🚏 ⏹ 🛑 ⏱ ⏱️\n"
          ]
        }
      ],
      "source": [
        "def translate_to_emoji_with_fallback(text):\n",
        "    \"\"\"\n",
        "    Translates the input text to an emoji using the trained T5 model.\n",
        "    Falls back to direct mapping if model output is empty or invalid.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    try:\n",
        "        # Generate output with the model\n",
        "        input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=32, truncation=True)\n",
        "        outputs = model.generate(input_ids, max_length=8, num_beams=4, early_stopping=True)\n",
        "        emoji_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Check if the output is valid\n",
        "        if emoji_output.strip() == \"\":\n",
        "            raise ValueError(\"Empty model output.\")\n",
        "\n",
        "        return emoji_output\n",
        "    except Exception:\n",
        "        # Fallback logic: Match words to the emoji dataset\n",
        "        words = text.lower().split()\n",
        "        matched_emojis = [combined_emoji_df[combined_emoji_df['label'].str.contains(word, na=False, case=False)]['emoji'].values for word in words]\n",
        "        matched_emojis = [item for sublist in matched_emojis for item in sublist]  # Flatten list\n",
        "\n",
        "        if matched_emojis:\n",
        "            return \" \".join(matched_emojis)\n",
        "        else:\n",
        "            return \"No matching emoji found.\"\n",
        "\n",
        "# Interactive loop with fallback\n",
        "def interactive_emoji_translator_with_fallback():\n",
        "    print(\"Welcome to the Enhanced Emoji Translator!\")\n",
        "    print(\"Type any phrase and press Enter to get an emoji.\")\n",
        "    print(\"Type 'exit' to quit the program.\")\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        phrase = input(\"Enter a phrase: \")\n",
        "\n",
        "        # Exit condition\n",
        "        if phrase.lower() == 'exit':\n",
        "            print(\"Exiting the Emoji Translator. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Translate the phrase to an emoji\n",
        "        try:\n",
        "            emoji_output = translate_to_emoji_with_fallback(phrase)\n",
        "            print(f\"Emoji: {emoji_output}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: Could not translate the phrase. {e}\")\n",
        "\n",
        "# Run the interactive translator with fallback\n",
        "interactive_emoji_translator_with_fallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYPVEOI_KDmc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWmVwnZvgCUo3FwXCxvybz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}