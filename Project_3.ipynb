{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/King-Rian/Project-3/blob/main/Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7NYz_bUmJ0Zj",
        "outputId": "0c16fb11-b8e0-47f7-bc32-6d61f914003b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7b88931-771a-428c-a035-498c2c52f884\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7b88931-771a-428c-a035-498c2c52f884\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving emojis.json.zip to emojis.json (2).zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Extract the ZIP file\n",
        "with zipfile.ZipFile('emojis.json.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Step 3: Load the extracted JSON file\n",
        "emoji_file = 'emojis.json'\n",
        "\n",
        "# Using pandas\n",
        "emoji_df = pd.read_json(emoji_file)\n",
        "print(\"Dataset loaded successfully. Sample data:\")\n",
        "print(emoji_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "M4cz5C-LLx1S",
        "outputId": "64da6503-d097-430a-d9bb-f10dc26cd9c4",
        "collapsed": true
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-806053d9-992e-47b4-a231-4ff7e3d03cf4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-806053d9-992e-47b4-a231-4ff7e3d03cf4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving emojis.json.zip to emojis.json (4).zip\n",
            "Dataset loaded successfully. Sample data:\n",
            "                                            category  \\\n",
            "0  Miscellaneous Symbols And Pictographs -> Emoji...   \n",
            "1  Miscellaneous Symbols And Pictographs -> Emoji...   \n",
            "2                                               None   \n",
            "3  Miscellaneous Symbols And Pictographs -> Emoji...   \n",
            "4                                               None   \n",
            "\n",
            "                                            keywords  \\\n",
            "0  [dark skin tone, hand, forbidden, gesture, wom...   \n",
            "1                     [dark skin tone, woman, guard]   \n",
            "2                 [racing, running, woman, marathon]   \n",
            "3  [gymnastics, medium-light skin tone, woman, ca...   \n",
            "4                                      [woman, golf]   \n",
            "\n",
            "                                          definition  \\\n",
            "0  The Woman Gesturing Not OK, Type-6 emoji is a ...   \n",
            "1  The Female Guard, Type-6 emoji is a sequence o...   \n",
            "2  The female version of the ?? Runner emoji. The...   \n",
            "3  The Woman Doing Cartwheel, Type-3 emoji is a s...   \n",
            "4  The female version of the ?? Golfer emoji. The...   \n",
            "\n",
            "                                unicode  \\\n",
            "0  U+1F645 U+1F3FF U+200D U+2640 U+FE0F   \n",
            "1  U+1F482 U+1F3FF U+200D U+2640 U+FE0F   \n",
            "2          U+1F3C3 U+200D U+2640 U+FE0F   \n",
            "3  U+1F938 U+1F3FC U+200D U+2640 U+FE0F   \n",
            "4   U+1F3CC U+FE0F U+200D U+2640 U+FE0F   \n",
            "\n",
            "                                         name shortcode  \\\n",
            "0          woman gesturing NO: dark skin tone      None   \n",
            "1                 woman guard: dark skin tone      None   \n",
            "2                               woman running      None   \n",
            "3  woman cartwheeling: medium-light skin tone      None   \n",
            "4                               woman golfing      None   \n",
            "\n",
            "                                              senses  \n",
            "0  {'adjectives': [{'bn:00104562a': ['Contrary to...  \n",
            "1  {'adjectives': [], 'verbs': [{'bn:00090041v': ...  \n",
            "2  {'adjectives': [{'bn:00109994a': ['Of advancin...  \n",
            "3  {'adjectives': [], 'verbs': [{'bn:00084605v': ...  \n",
            "4  {'adjectives': [], 'verbs': [{'bn:00088979v': ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean the data"
      ],
      "metadata": {
        "id": "NJ3IV9jDrSxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types and column names\n",
        "emoji_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBH8UAhotReT",
        "outputId": "098d529e-3c9e-4389-f5a8-f0684022b28f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2389 entries, 0 to 2388\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   category    1988 non-null   object\n",
            " 1   keywords    2389 non-null   object\n",
            " 2   definition  2389 non-null   object\n",
            " 3   unicode     2389 non-null   object\n",
            " 4   name        2389 non-null   object\n",
            " 5   shortcode   845 non-null    object\n",
            " 6   senses      2389 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 130.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values\n",
        "emoji_df.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "tuZuML2CjYNa",
        "outputId": "5753e91d-56cc-4944-c253-37e9a70a7c62"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category       401\n",
              "keywords         0\n",
              "definition       0\n",
              "unicode          0\n",
              "name             0\n",
              "shortcode     1544\n",
              "senses           0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keywords</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>definition</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unicode</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shortcode</th>\n",
              "      <td>1544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>senses</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show unique values for shortcode\n",
        "unique_values = emoji_df['shortcode'].unique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHVQtyD2lGSc",
        "outputId": "58732518-bba8-4aa0-f421-9147f2462f6d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None ':zero:' ':m:' ':accept:' ':ideograph_advantage:' ':u55b6:'\n",
            " ':u5272:' ':u7533:' ':u6708:' ':u6709:' ':u6e80:' ':u5408:' ':u7a7a:'\n",
            " ':u7981:' ':u6307:' ':u7121:' ':sa:' ':koko:' ':kr:' ':cn:'\n",
            " ':hourglass_flowing_sand:' ':alarm_clock:' ':arrow_double_down:'\n",
            " ':arrow_double_up:' ':rewind:' ':fast_forward:' ':eight:' ':de:' ':four:'\n",
            " ':vs:' ':up:' ':sos:' ':ok:' ':ng:' ':new:' ':id:' ':free:' ':cool:'\n",
            " ':cl:' ':ab:' ':parking:' ':o2:' ':b:' ':a:' ':hourglass:' ':watch:'\n",
            " ':ru:' ':black_joker:' ':seven:' ':three:' ':arrow_heading_down:'\n",
            " ':arrow_heading_up:' ':registered:' ':copyright:' ':left_luggage:'\n",
            " ':baggage_claim:' ':customs:' ':passport_control:' ':bathtub:' ':bath:'\n",
            " ':shower:' ':wc:' ':toilet:' ':baby_symbol:' ':restroom:' ':womens:'\n",
            " ':mens:' ':children_crossing:' ':no_pedestrians:' ':walking:'\n",
            " ':mountain_bicyclist:' ':bicyclist:' ':no_bicycles:' ':bike:'\n",
            " ':non-potable_water:' ':potable_water:' ':do_not_litter:'\n",
            " ':put_litter_in_its_place:' ':no_smoking:' ':smoking:' ':no_entry_sign:'\n",
            " ':door:' ':triangular_flag_on_post:' ':rotating_light:' ':construction:'\n",
            " ':vertical_traffic_light:' ':traffic_light:' ':speedboat:' ':rowboat:'\n",
            " ':ship:' ':aerial_tramway:' ':mountain_cableway:' ':mahjong:'\n",
            " ':suspension_railway:' ':mountain_railway:' ':monorail:' ':tractor:'\n",
            " ':articulated_lorry:' ':truck:' ':blue_car:' ':oncoming_automobile:'\n",
            " ':car:,:red_car:' ':oncoming_taxi:' ':taxi:' ':oncoming_police_car:'\n",
            " ':police_car:' ':fire_engine:' ':ambulance:' ':minibus:' ':busstop:'\n",
            " ':trolleybus:' ':oncoming_bus:' ':bus:' ':train:' ':tram:' ':station:'\n",
            " ':light_rail:' ':metro:' ':train2:' ':bullettrain_front:'\n",
            " ':bullettrain_side:' ':railway_car:' ':steam_locomotive:' ':helicopter:'\n",
            " ':rocket:' ':pray:' ':two:' ':person_with_pouting_face:'\n",
            " ':person_frowning:' ':raised_hands:' ':raising_hand:' ':speak_no_evil:'\n",
            " ':hear_no_evil:' ':see_no_evil:' ':bow:' ':ok_woman:' ':no_good:'\n",
            " ':scream_cat:' ':crying_cat_face:' ':pouting_cat:' ':kissing_cat:'\n",
            " ':smirk_cat:' ':heart_eyes_cat:' ':smiley_cat:' ':joy_cat:' ':smile_cat:'\n",
            " ':mask:' ':no_mouth:' ':dizzy_face:' ':sleeping:' ':flushed:'\n",
            " ':astonished:' ':scream:' ':cold_sweat:' ':hushed:' ':open_mouth:'\n",
            " ':sob:' ':grimacing:' ':tired_face:' ':sleepy:' ':weary:' ':fearful:'\n",
            " ':anguished:' ':frowning:' ':disappointed_relieved:' ':triumph:'\n",
            " ':persevere:' ':cry:' ':rage:' ':angry:' ':worried:' ':disappointed:'\n",
            " ':stuck_out_tongue_closed_eyes:' ':stuck_out_tongue_winking_eye:'\n",
            " ':stuck_out_tongue:' ':kissing_closed_eyes:' ':kissing_smiling_eyes:'\n",
            " ':kissing_heart:' ':kissing:' ':confounded:' ':confused:' ':pensive:'\n",
            " ':sweat:' ':unamused:' ':expressionless:' ':neutral_face:' ':smirk:'\n",
            " ':sunglasses:' ':heart_eyes:' ':relieved:' ':yum:' ':blush:' ':wink:'\n",
            " ':smiling_imp:' ':innocent:' ':laughing:,:satisfied:' ':sweat_smile:'\n",
            " ':smile:' ':smiley:' ':joy:' ':grin:' ':grinning:' ':hash:'\n",
            " ':arrow_right_hook:' ':leftwards_arrow_with_hook:' ':moyai:' ':japan:'\n",
            " ':statue_of_liberty:' ':tokyo_tower:' ':mount_fuji:' ':secret:'\n",
            " ':congratulations:' ':arrow_lower_left:' ':arrow_lower_right:'\n",
            " ':arrow_upper_right:' ':arrow_upper_left:' ':arrow_up_down:'\n",
            " ':left_right_arrow:' ':loop:' ':curly_loop:' ':arrow_right:'\n",
            " ':information_source:' ':tm:' ':es:' ':clock1230:' ':clock1130:'\n",
            " ':clock1030:' ':clock930:' ':clock830:' ':heavy_division_sign:'\n",
            " ':clock730:' ':heavy_minus_sign:' ':clock630:' ':heavy_plus_sign:'\n",
            " ':clock530:' ':clock430:' ':clock330:' ':clock230:' ':clock130:'\n",
            " ':clock12:' ':clock11:' ':clock10:' ':clock9:' ':clock8:' ':clock7:'\n",
            " ':clock6:' ':clock5:' ':clock4:' ':clock3:' ':clock2:' ':clock1:'\n",
            " ':arrow_down_small:' ':arrow_up_small:' ':small_red_triangle_down:'\n",
            " ':small_red_triangle:' ':small_blue_diamond:' ':small_orange_diamond:'\n",
            " ':large_blue_diamond:' ':fr:' ':large_orange_diamond:'\n",
            " ':large_blue_circle:' ':red_circle:' ':white_square_button:'\n",
            " ':black_square_button:' ':trident:' ':beginner:' ':heart:'\n",
            " ':six_pointed_star:' ':crystal_ball:' ':telescope:' ':microscope:'\n",
            " ':gun:' ':hocho:,:knife:' ':nut_and_bolt:' ':hammer:' ':wrench:'\n",
            " ':flashlight:' ':fire:' ':abc:' ':symbols:'\n",
            " ':exclamation:,:heavy_exclamation_mark:' ':1234:' ':abcd:'\n",
            " ':grey_exclamation:' ':capital_abcd:' ':grey_question:' ':question:'\n",
            " ':keycap_ten:' ':underage:' ':top:' ':soon:' ':on:' ':end:'\n",
            " ':negative_squared_cross_mark:' ':x:' ':back:' ':radio_button:' ':link:'\n",
            " ':bookmark:' ':no_bell:' ':bell:' ':unlock:' ':sparkle:' ':lock:' ':key:'\n",
            " ':closed_lock_with_key:' ':snowflake:' ':lock_with_ink_pen:'\n",
            " ':mag_right:' ':mag:' ':electric_plug:' ':battery:' ':loud_sound:'\n",
            " ':sound:' ':speaker:' ':mute:' ':high_brightness:' ':low_brightness:'\n",
            " ':arrows_counterclockwise:' ':arrows_clockwise:' ':repeat_one:'\n",
            " ':repeat:' ':twisted_rightwards_arrows:' ':eight_pointed_black_star:'\n",
            " ':eight_spoked_asterisk:' ':sparkles:' ':heavy_multiplication_x:'\n",
            " ':heavy_check_mark:' ':black_nib:' ':gb:,:uk:' ':pencil2:' ':v:'\n",
            " ':hand:,:raised_hand:' ':fist:' ':email:,:envelope:' ':airplane:'\n",
            " ':white_check_mark:' ':scissors:' ':vhs:' ':radio:' ':tv:'\n",
            " ':video_camera:' ':camera:' ':signal_strength:' ':no_mobile_phones:'\n",
            " ':mobile_phone_off:' ':vibration_mode:' ':calling:' ':iphone:'\n",
            " ':newspaper:' ':postal_horn:' ':postbox:' ':mailbox_with_no_mail:'\n",
            " ':mailbox_with_mail:' ':mailbox:' ':mailbox_closed:'\n",
            " ':envelope_with_arrow:' ':incoming_envelope:' ':e-mail:' ':package:'\n",
            " ':inbox_tray:' ':outbox_tray:' ':mega:' ':loudspeaker:' ':satellite:'\n",
            " ':fax:' ':six:' ':it:' ':pager:' ':telephone_receiver:' ':memo:,:pencil:'\n",
            " ':scroll:' ':name_badge:' ':books:' ':orange_book:' ':blue_book:'\n",
            " ':green_book:' ':book:,:open_book:' ':closed_book:'\n",
            " ':notebook_with_decorative_cover:' ':notebook:' ':ledger:'\n",
            " ':bookmark_tabs:' ':triangular_ruler:' ':straight_ruler:' ':paperclip:'\n",
            " ':round_pushpin:' ':pushpin:' ':clipboard:' ':bar_chart:' ':fuelpump:'\n",
            " ':tent:' ':chart_with_downwards_trend:' ':chart_with_upwards_trend:'\n",
            " ':card_index:' ':calendar:' ':date:' ':page_facing_up:'\n",
            " ':page_with_curl:' ':open_file_folder:' ':file_folder:'\n",
            " ':boat:,:sailboat:' ':dvd:' ':golf:' ':fountain:' ':cd:' ':floppy_disk:'\n",
            " ':minidisc:' ':briefcase:' ':computer:' ':seat:' ':church:' ':chart:'\n",
            " ':money_with_wings:' ':pound:' ':euro:' ':dollar:' ':yen:'\n",
            " ':credit_card:' ':heavy_dollar_sign:' ':currency_exchange:' ':moneybag:'\n",
            " ':100:' ':white_flower:' ':thought_balloon:' ':speech_balloon:' ':dizzy:'\n",
            " ':muscle:' ':hankey:,:poop:,:shit:' ':dash:' ':droplet:' ':sweat_drops:'\n",
            " ':boom:,:collision:' ':zzz:' ':bomb:' ':anger:' ':bulb:'\n",
            " ':diamond_shape_with_a_dot_inside:' ':no_entry:' ':ophiuchus:' ':jp:'\n",
            " ':partly_sunny:' ':snowman:' ':baseball:' ':soccer:' ':black_circle:'\n",
            " ':white_circle:' ':zap:' ':warning:' ':interrobang:' ':bangbang:'\n",
            " ':heart_decoration:' ':revolving_hearts:' ':gift_heart:' ':purple_heart:'\n",
            " ':yellow_heart:' ':green_heart:' ':blue_heart:' ':cupid:' ':heartpulse:'\n",
            " ':sparkling_heart:' ':two_hearts:' ':broken_heart:' ':heartbeat:'\n",
            " ':wedding:' ':couple_with_heart:' ':bouquet:' ':couplekiss:' ':gem:'\n",
            " ':ring:' ':love_letter:' ':kiss:' ':pill:' ':syringe:' ':barber:'\n",
            " ':haircut:' ':massage:' ':nail_care:' ':lipstick:' ':dancer:'\n",
            " ':guardsman:' ':information_desk_person:' ':skull:' ':imp:'\n",
            " ':space_invader:' ':alien:' ':angel:' ':ghost:' ':japanese_goblin:'\n",
            " ':japanese_ogre:' ':princess:' ':construction_worker:' ':baby:'\n",
            " ':older_woman:' ':older_man:' ':man_with_turban:' ':man_with_gua_pi_mao:'\n",
            " ':person_with_blond_hair:' ':bride_with_veil:' ':dancers:' ':cop:'\n",
            " ':two_women_holding_hands:' ':two_men_holding_hands:' ':couple:'\n",
            " ':family:' ':woman:' ':man:' ':girl:' ':boy:' ':busts_in_silhouette:'\n",
            " ':bust_in_silhouette:' ':footprints:' ':boot:' ':sandal:' ':high_heel:'\n",
            " ':anchor:' ':athletic_shoe:' ':mans_shoe:,:shoe:' ':pouch:' ':handbag:'\n",
            " ':purse:' ':womans_clothes:' ':bikini:' ':kimono:' ':dress:' ':jeans:'\n",
            " ':shirt:,:tshirt:' ':us:' ':necktie:' ':eyeglasses:' ':womans_hat:'\n",
            " ':crown:' ':open_hands:' ':clap:' ':-1:,:thumbsdown:' ':+1:,:thumbsup:'\n",
            " ':ok_hand:' ':wave:' ':wheelchair:' ':facepunch:,:punch:' ':recycle:'\n",
            " ':point_right:' ':point_left:' ':point_down:' ':point_up_2:' ':tongue:'\n",
            " ':lips:' ':nose:' ':ear:' ':eyes:' ':feet:,:paw_prints:' ':pig_nose:'\n",
            " ':panda_face:' ':bear:' ':wolf:' ':hamster:' ':frog:' ':pig:' ':dog:'\n",
            " ':monkey_face:' ':horse:' ':hotsprings:' ':whale:' ':dragon_face:'\n",
            " ':diamonds:' ':cat:' ':hearts:' ':rabbit:' ':clubs:' ':spades:' ':tiger:'\n",
            " ':cow:' ':mouse:' ':dolphin:,:flipper:' ':camel:' ':dromedary_camel:'\n",
            " ':poodle:' ':koala:' ':penguin:' ':bird:' ':hatched_chick:'\n",
            " ':baby_chick:' ':hatching_chick:' ':turtle:' ':blowfish:'\n",
            " ':tropical_fish:' ':pisces:' ':aquarius:' ':capricorn:' ':sagittarius:'\n",
            " ':fish:' ':beetle:' ':bee:,:honeybee:' ':ant:' ':bug:' ':scorpius:'\n",
            " ':shell:' ':libra:' ':virgo:' ':leo:' ':cancer:' ':gemini:' ':octopus:'\n",
            " ':elephant:' ':boar:' ':pig2:' ':dog2:' ':taurus:' ':chicken:' ':aries:'\n",
            " ':rooster:' ':monkey:' ':sheep:' ':goat:' ':ram:' ':racehorse:' ':snake:'\n",
            " ':snail:' ':whale2:' ':crocodile:' ':relaxed:' ':dragon:' ':cat2:'\n",
            " ':rabbit2:' ':leopard:' ':tiger2:' ':cow2:' ':water_buffalo:' ':ox:'\n",
            " ':mouse2:' ':rat:' ':point_up:' ':coffee:' ':umbrella:'\n",
            " ':ballot_box_with_check:' ':phone:,:telephone:' ':cloud:' ':sunny:'\n",
            " ':nine:' ':five:' ':one:' ':european_castle:' ':japanese_castle:'\n",
            " ':izakaya_lantern:,:lantern:' ':factory:' ':department_store:' ':school:'\n",
            " ':convenience_store:' ':love_hotel:' ':hotel:' ':atm:' ':bank:'\n",
            " ':hospital:' ':european_post_office:' ':post_office:' ':office:'\n",
            " ':house_with_garden:' ':house:' ':swimmer:' ':black_medium_small_square:'\n",
            " ':white_medium_small_square:' ':black_medium_square:'\n",
            " ':white_medium_square:' ':rugby_football:' ':football:' ':horse_racing:'\n",
            " ':trophy:' ':surfer:' ':runner:,:running:' ':snowboarder:'\n",
            " ':checkered_flag:' ':basketball:' ':ski:' ':tennis:'\n",
            " ':running_shirt_with_sash:' ':musical_score:' ':violin:' ':trumpet:'\n",
            " ':musical_keyboard:' ':guitar:' ':saxophone:' ':notes:' ':musical_note:'\n",
            " ':flower_playing_cards:' ':bowling:' ':game_die:' ':8ball:'\n",
            " ':slot_machine:' ':dart:' ':video_game:' ':performing_arts:' ':clapper:'\n",
            " ':ticket:' ':circus_tent:' ':tophat:' ':art:' ':headphones:' ':cinema:'\n",
            " ':movie_camera:' ':microphone:' ':fishing_pole_and_fish:'\n",
            " ':roller_coaster:' ':ferris_wheel:' ':carousel_horse:' ':arrow_backward:'\n",
            " ':arrow_forward:' ':white_small_square:' ':black_small_square:'\n",
            " ':part_alternation_mark:' ':wavy_dash:' ':mortar_board:'\n",
            " ':school_satchel:' ':rice_scene:' ':wind_chime:' ':flags:' ':o:'\n",
            " ':dolls:' ':bamboo:' ':crossed_flags:' ':tanabata_tree:'\n",
            " ':confetti_ball:' ':star:' ':tada:' ':balloon:' ':sparkler:'\n",
            " ':fireworks:' ':santa:' ':christmas_tree:' ':jack_o_lantern:'\n",
            " ':birthday:' ':gift:' ':ribbon:' ':baby_bottle:' ':beers:' ':beer:'\n",
            " ':tropical_drink:' ':cocktail:' ':wine_glass:' ':sake:' ':tea:'\n",
            " ':fork_and_knife:' ':egg:' ':stew:' ':bento:' ':cake:' ':honey_pot:'\n",
            " ':custard:' ':lollipop:' ':candy:' ':chocolate_bar:' ':cookie:'\n",
            " ':doughnut:' ':ice_cream:' ':shaved_ice:' ':icecream:' ':fish_cake:'\n",
            " ':fried_shrimp:' ':sushi:' ':oden:' ':dango:' ':sweet_potato:' ':fries:'\n",
            " ':bread:' ':spaghetti:' ':ramen:' ':curry:' ':rice:' ':rice_ball:'\n",
            " ':rice_cracker:' ':poultry_leg:' ':meat_on_bone:' ':pizza:'\n",
            " ':white_large_square:' ':hamburger:' ':black_large_square:'\n",
            " ':strawberry:' ':cherries:' ':peach:' ':pear:' ':green_apple:' ':apple:'\n",
            " ':pineapple:' ':banana:' ':lemon:' ':tangerine:' ':watermelon:' ':melon:'\n",
            " ':grapes:' ':eggplant:' ':tomato:' ':mushroom:' ':leaves:'\n",
            " ':fallen_leaf:' ':maple_leaf:' ':four_leaf_clover:' ':arrow_down:'\n",
            " ':arrow_up:' ':herb:' ':arrow_left:' ':ear_of_rice:' ':corn:' ':blossom:'\n",
            " ':sunflower:' ':hibiscus:' ':rose:' ':cherry_blossom:' ':tulip:'\n",
            " ':cactus:' ':palm_tree:' ':deciduous_tree:' ':evergreen_tree:'\n",
            " ':seedling:' ':chestnut:' ':stars:' ':star2:' ':sun_with_face:'\n",
            " ':full_moon_with_face:' ':last_quarter_moon_with_face:'\n",
            " ':first_quarter_moon_with_face:' ':new_moon_with_face:' ':crescent_moon:'\n",
            " ':waning_crescent_moon:' ':last_quarter_moon:' ':waning_gibbous_moon:'\n",
            " ':full_moon:' ':moon:,:waxing_gibbous_moon:' ':first_quarter_moon:'\n",
            " ':waxing_crescent_moon:' ':new_moon:' ':globe_with_meridians:'\n",
            " ':earth_asia:' ':earth_americas:' ':earth_africa:' ':milky_way:'\n",
            " ':volcano:' ':ocean:' ':bridge_at_night:' ':rainbow:' ':city_sunrise:'\n",
            " ':city_sunset:' ':sunrise:' ':sunrise_over_mountains:'\n",
            " ':night_with_stars:' ':closed_umbrella:' ':foggy:' ':cyclone:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show unique values for category\n",
        "unique_values = emoji_df['category'].unique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ch8custqkPYq",
        "outputId": "9f7134d4-4b78-4b9c-8695-a2dff001539f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Miscellaneous Symbols And Pictographs -> Emoji modifiers' None\n",
            " 'Miscellaneous Symbols And Pictographs -> Hand symbols'\n",
            " 'Supplemental Symbols And Pictographs -> Animal symbols'\n",
            " 'Supplemental Symbols And Pictographs -> Food symbol'\n",
            " 'Supplemental Symbols And Pictographs -> Miscellaneous mark'\n",
            " 'Miscellaneous Symbols -> Map symbol from ARIB STD B24'\n",
            " 'Supplemental Symbols And Pictographs -> Portrait and role symbols'\n",
            " 'Supplemental Symbols And Pictographs -> Emoticon faces'\n",
            " 'Supplemental Symbols And Pictographs -> Hand symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Sport symbols'\n",
            " 'Enclosed Alphanumerics -> Circled Latin letters'\n",
            " 'Miscellaneous Symbols And Pictographs -> Portrait and role symbols'\n",
            " 'Enclosed Ideographic Supplement -> Circled ideographs'\n",
            " 'Enclosed Ideographic Supplement -> Squared ideographs'\n",
            " 'Enclosed Ideographic Supplement -> Squared ideographs and kana from ARIB STD B24'\n",
            " 'Enclosed Ideographic Supplement -> Squared katakana'\n",
            " 'Miscellaneous Technical -> User interface symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Fairy tale symbols'\n",
            " 'Miscellaneous Technical -> Keyboard and UI symbols'\n",
            " 'Enclosed Alphanumeric Supplement -> Squared Latin letter sequences'\n",
            " 'Enclosed Alphanumeric Supplement -> White on black squared Latin letters'\n",
            " 'Miscellaneous Technical -> Keyboard symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Facial parts symbols'\n",
            " 'Emoticons -> Gesture symbols' 'Playing Cards -> Joker'\n",
            " 'Supplemental Arrows B -> Miscellaneous curved arrows'\n",
            " 'Latin 1 Supplement -> Latin-1 punctuation and symbols'\n",
            " 'Transport And Map Symbols -> Vehicles'\n",
            " 'Transport And Map Symbols -> Miscellaneous mark'\n",
            " 'Transport And Map Symbols -> Signage and other symbols'\n",
            " 'Transport And Map Symbols -> Accommodation symbol'\n",
            " 'Transport And Map Symbols -> Traffic signs'\n",
            " 'Mahjong Tiles -> Dragon tiles'\n",
            " 'Miscellaneous Symbols And Pictographs -> Role symbol'\n",
            " 'Emoticons -> Faces' 'Emoticons -> Cat faces'\n",
            " 'Miscellaneous Symbols And Pictographs -> Celebration symbols'\n",
            " 'Arrows -> Arrows with modifications'\n",
            " 'Miscellaneous Symbols And Pictographs -> Cultural symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Map symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Ballot symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Bubble symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Rating symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Miscellaneous mark'\n",
            " 'Miscellaneous Symbols And Pictographs -> User interface symbols'\n",
            " 'Enclosed CJK Letters And Months -> Circled ideographs'\n",
            " 'Miscellaneous Symbols And Pictographs -> Office symbols'\n",
            " 'Arrows -> Simple arrows'\n",
            " 'Miscellaneous Symbols And Pictographs -> Computer symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Heart symbol'\n",
            " 'Dingbats -> Miscellaneous' 'Dingbats -> Dingbat arrow'\n",
            " 'Letterlike Symbols -> Letterlike symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Comic style symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Communication symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Game symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Animal symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Clock face symbols'\n",
            " 'Dingbats -> Heavy variants of arithmetic symbols'\n",
            " 'Miscellaneous Symbols -> Pointing hand symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Religious symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Geometric shapes'\n",
            " 'Dingbats -> Punctuation mark ornaments'\n",
            " 'Miscellaneous Symbols And Pictographs -> Tool symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> User interface input status symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Enclosed alphanumeric symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Words with arrows'\n",
            " 'Dingbats -> Stars, asterisks and snowflakes'\n",
            " 'Dingbats -> Stars and asterisks' 'Dingbats -> Crosses'\n",
            " 'Miscellaneous Symbols And Pictographs -> Audio and video symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Money symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Japanese school grade symbols'\n",
            " 'Miscellaneous Symbols -> Traffic sign from ARIB STD B24'\n",
            " 'Miscellaneous Symbols -> Zodiacal symbol'\n",
            " 'Miscellaneous Symbols -> Weather symbols from ARIB STD B24'\n",
            " 'Miscellaneous Symbols -> Sport symbols'\n",
            " 'Miscellaneous Symbols -> Genealogical symbols'\n",
            " 'Miscellaneous Symbols -> Circles'\n",
            " 'Miscellaneous Symbols -> Miscellaneous mark'\n",
            " 'General Punctuation -> Double punctuation for vertical text'\n",
            " 'Miscellaneous Symbols And Pictographs -> Romance symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Medical symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Personal care symbols'\n",
            " 'Miscellaneous Symbols -> Dictionary and map symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Clothing and accessories'\n",
            " 'Miscellaneous Symbols -> Recycling symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Animal faces'\n",
            " 'Miscellaneous Symbols -> Playing card symbols'\n",
            " 'Miscellaneous Symbols -> Astrological signs'\n",
            " 'Miscellaneous Symbols -> Emoticons'\n",
            " 'Miscellaneous Symbols -> Religious and political symbols'\n",
            " 'Miscellaneous Symbols -> Warning signs'\n",
            " 'Miscellaneous Symbols -> Weather symbol'\n",
            " 'Miscellaneous Symbols -> Weather and astrological symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Rosettes'\n",
            " 'Miscellaneous Symbols And Pictographs -> Flag symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Building and map symbols'\n",
            " 'Geometric Shapes -> Geometric shapes'\n",
            " 'Miscellaneous Symbols And Pictographs -> Musical symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Entertainment symbols'\n",
            " 'CJK Symbols And Punctuation -> Other CJK punctuation'\n",
            " 'CJK Symbols And Punctuation -> CJK symbols'\n",
            " 'Miscellaneous Symbols And Arrows -> Traffic sign from ARIB STD B24'\n",
            " 'Miscellaneous Symbols And Arrows -> Stars'\n",
            " 'Miscellaneous Symbols And Pictographs -> Beverage and food symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Accommodation symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Beverage symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Food symbol'\n",
            " 'Miscellaneous Symbols And Arrows -> Squares'\n",
            " 'Miscellaneous Symbols And Pictographs -> Fruit and vegetable symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Plant symbols'\n",
            " 'Miscellaneous Symbols And Arrows -> White and black arrows'\n",
            " 'Miscellaneous Symbols And Pictographs -> Weather symbol'\n",
            " 'Miscellaneous Symbols And Pictographs -> Moon, sun, and star symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Globe symbols'\n",
            " 'Miscellaneous Symbols And Pictographs -> Weather, landscape, and sky symbols']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop category and shortcode columns to improve model processing\n",
        "emoji_df = emoji_df.drop(columns=['category', 'shortcode'])"
      ],
      "metadata": {
        "id": "bIjaIiGyxcb1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_df.info()"
      ],
      "metadata": {
        "id": "SKteLYKh0R95",
        "outputId": "c9d8e2da-f567-4378-a535-c40154b19ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2389 entries, 0 to 2388\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   keywords    2389 non-null   object\n",
            " 1   definition  2389 non-null   object\n",
            " 2   unicode     2389 non-null   object\n",
            " 3   name        2389 non-null   object\n",
            " 4   senses      2389 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 93.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data\n"
      ],
      "metadata": {
        "id": "Xlfmldv1zdml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Preprocess the data to map context words to emojis\n",
        "def map_phrases_to_emojis(df):\n",
        "    mapping = {}\n",
        "    for _, row in df.iterrows():\n",
        "        for word in row.get(\"context_words\", []):  # Safely access context_words\n",
        "            mapping[word] = row[\"emoji\"]\n",
        "    return mapping\n",
        "\n",
        "emoji_mapping = map_phrases_to_emojis(emoji_df)\n",
        "print(\"Sample emoji mapping:\", list(emoji_mapping.items())[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKxD6B4nNtra",
        "outputId": "32d48d9b-de9f-4eb7-d828-924e5e71a676"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample emoji mapping: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Redownload 'punkt' tokenizer\n",
        "nltk.download('punkt', force=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HNQnmkLOH4A",
        "outputId": "19e85859-7244-46f0-b045-c38c7a8bc36e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "\n",
        "# Manually set the NLTK data directory\n",
        "nltk_data_path = '/root/nltk_data'\n",
        "os.makedirs(nltk_data_path, exist_ok=True)\n",
        "nltk.data.path.append(nltk_data_path)\n",
        "\n",
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt', download_dir=nltk_data_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuGAbivwOKgx",
        "outputId": "78b5bb20-bbdb-452d-fbda-ff5835e9c838"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "\n",
        "# Download 'punkt_tab'\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Ensure NLTK data path is set correctly (if needed)\n",
        "nltk_data_path = '/root/nltk_data'\n",
        "os.makedirs(nltk_data_path, exist_ok=True)  # Create if doesn't exist\n",
        "nltk.data.path.append(nltk_data_path)      # Add to NLTK's search path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym5N_hgBOu0A",
        "outputId": "3979430e-3ffd-4dde-d194-c3fb57493358"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 5: Tokenize and map text to emoji sequences\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return [emoji_mapping.get(token, token) for token in tokens]\n",
        "\n",
        "# Example text preprocessing\n",
        "text = \"I love sunny weather\"\n",
        "emoji_sequence = tokenize_text(text)\n",
        "print(\"Input Text:\", text)\n",
        "print(\"Emoji Sequence:\", emoji_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhyCHTNUNykL",
        "outputId": "5ccd3d26-5d6b-48f2-8b73-254fb8252b1d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: I love sunny weather\n",
            "Emoji Sequence: ['i', 'love', 'sunny', 'weather']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained transformer model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Encode input text\n",
        "input_text = \"I love sunny weather\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# Generate emoji sequence\n",
        "outputs = model.generate(inputs[\"input_ids\"], max_length=10, num_return_sequences=1)\n",
        "emoji_sequence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Emoji Sequence from Model:\", emoji_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7E6_dcFO25_",
        "outputId": "1f91db35-9172-45f6-a06c-00d3423dfce5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Emoji Sequence from Model: i love love love love love love love love\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install vaderSentiment"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUwPSkk0Pekl",
        "outputId": "e9ff5fc1-8ecf-48f4-e494-9ff661fd47c9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Refine emoji selection based on sentiment\n",
        "def refine_with_sentiment(text, emoji_sequence):\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    tone = \"positive\" if sentiment[\"compound\"] > 0 else \"negative\"\n",
        "    refined_sequence = [emoji + (\"😊\" if tone == \"positive\" else \"😢\") for emoji in emoji_sequence]\n",
        "    return refined_sequence\n",
        "\n",
        "# Split the emoji sequence into a list of individual emojis\n",
        "emoji_sequence_list = list(emoji_sequence)\n",
        "\n",
        "refined_sequence = refine_with_sentiment(input_text, emoji_sequence_list)\n",
        "print(\"Refined Emoji Sequence Based on Sentiment:\", refined_sequence)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gThgN9IbPfKm",
        "outputId": "56d4428f-bf89-480f-fc50-d1d3fa660b0e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Emoji Sequence Based on Sentiment: ['i😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊', ' 😊', 'l😊', 'o😊', 'v😊', 'e😊']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Refine emoji selection based on sentiment\n",
        "def refine_with_sentiment(text, emoji_sequence):\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    tone = \"positive\" if sentiment[\"compound\"] > 0 else \"negative\"\n",
        "    refined_sequence = [emoji + (\"😊\" if tone == \"positive\" else \"😢\") for emoji in emoji_sequence]\n",
        "    return refined_sequence\n",
        "\n",
        "refined_sequence = refine_with_sentiment(input_text, emoji_sequence.split())\n",
        "print(\"Refined Emoji Sequence Based on Sentiment:\", refined_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axryKQr9PJvv",
        "outputId": "7d6d5ad1-4b22-4419-cad2-65ae010fd4bd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Emoji Sequence Based on Sentiment: ['i😊', 'love😊', 'love😊', 'love😊', 'love😊', 'love😊', 'love😊', 'love😊', 'love😊']\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from transformers import AdamW, T5Tokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Load a pre-trained T5 tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")  # Use T5 tokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Simple training loop (illustration, adjust as needed for your dataset)\n",
        "for epoch in range(10):  # Iterate through epochs\n",
        "    model.train()\n",
        "    inputs = tokenizer(\"I love sunny weather\", return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    labels = tokenizer(\"😊☀️\", return_tensors=\"pt\", max_length=10, truncation=True)[\"input_ids\"]\n",
        "\n",
        "    # Remove token_type_ids from inputs if present\n",
        "    if \"token_type_ids\" in inputs:\n",
        "        del inputs[\"token_type_ids\"]\n",
        "\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Loss: {loss.item()}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsKywipSP3HL",
        "outputId": "a0bb949d-08cf-4e23-9652-2246c444c8ea"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 4.525148868560791\n",
            "Epoch 2 Loss: 2.609675168991089\n",
            "Epoch 3 Loss: 3.2535552978515625\n",
            "Epoch 4 Loss: 4.122931003570557\n",
            "Epoch 5 Loss: 3.5338964462280273\n",
            "Epoch 6 Loss: 2.5128514766693115\n",
            "Epoch 7 Loss: 3.537613868713379\n",
            "Epoch 8 Loss: 1.5669277906417847\n",
            "Epoch 9 Loss: 2.106816053390503\n",
            "Epoch 10 Loss: 1.6705074310302734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Simple training loop (illustration, adjust as needed for your dataset)\n",
        "for epoch in range(10):  # Iterate through epochs\n",
        "    model.train()\n",
        "    inputs = tokenizer(\"I love sunny weather\", return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    labels = tokenizer(\"😊☀️\", return_tensors=\"pt\", max_length=10, truncation=True)[\"input_ids\"]\n",
        "\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2eGfV9TPKQk",
        "outputId": "c15cc5a6-2d42-4255-897f-2881b9df0f78",
        "collapsed": true
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.1596747636795044\n",
            "Epoch 2 Loss: 0.7002083659172058\n",
            "Epoch 3 Loss: 1.0428745746612549\n",
            "Epoch 4 Loss: 0.8993375897407532\n",
            "Epoch 5 Loss: 0.7519550323486328\n",
            "Epoch 6 Loss: 0.31472471356391907\n",
            "Epoch 7 Loss: 1.7767057418823242\n",
            "Epoch 8 Loss: 1.0772424936294556\n",
            "Epoch 9 Loss: 0.5401368141174316\n",
            "Epoch 10 Loss: 0.4444301128387451\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install python-Levenshtein"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NYcPWiERdDP",
        "outputId": "33899d52-c862-49bf-aa10-3c4dbeced5b2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: Levenshtein==0.26.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.26.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.10.1)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from Levenshtein import distance as levenshtein_distance\n",
        "\n",
        "# Evaluate emoji sequence matching\n",
        "def evaluate_sequences(predicted, actual):\n",
        "    score = levenshtein_distance(predicted, actual)\n",
        "    return score\n",
        "\n",
        "predicted_sequence = \"😊☀️\"\n",
        "actual_sequence = \"😊☀️\"\n",
        "score = evaluate_sequences(predicted_sequence, actual_sequence)\n",
        "print(\"Levenshtein Distance Between Sequences:\", score)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyhp6qv-Rdsa",
        "outputId": "fb926a63-4563-411d-941e-5a7665d96144"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levenshtein Distance Between Sequences: 0\n"
          ]
        }
      ]
    }
  ]
}